{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ab0d668",
   "metadata": {},
   "source": [
    "# Split data to train, validate and test subsets\n",
    "\n",
    "Random split: 60% for training, 20% for validation, 20% for testing\n",
    "\n",
    "Temporal split: 2019-2020 for training, 20221-2023 for testing\n",
    "\n",
    "Input: \n",
    "- `../data/preprocessed_data/Atlantic_2019_03/normalized`\n",
    "\n",
    "Output: \n",
    "- `../data/randomsplit/train`\n",
    "- `../data/randomsplit/test`\n",
    "- `../data/temporalsplit/train`\n",
    "- `../data/temporalsplit/test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20728b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30afc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../data/preprocessed_data/Atlantic_2019_03/normalized/'\n",
    "random_train_dir = \"../data/randomsplit/train\"\n",
    "random_val_dir = \"../data/randomsplit/val\"\n",
    "random_test_dir = \"../data/randomsplit/test\"\n",
    "\n",
    "temporal_train_dir = \"../data/temporalsplit/train\"\n",
    "temporal_val_dir = \"../data/temporalsplit/val\"\n",
    "temporal_test_dir = \"../data/temporalsplit/test\"\n",
    "\n",
    "\n",
    "file_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "os.makedirs(random_train_dir, exist_ok=True)\n",
    "os.makedirs(random_val_dir, exist_ok=True)\n",
    "os.makedirs(random_test_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(temporal_train_dir, exist_ok=True)\n",
    "os.makedirs(temporal_val_dir, exist_ok=True)\n",
    "os.makedirs(temporal_test_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ab0751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data and make sure the proportion in train and test set are equal\n",
    "def getRandomSplit(data, size):\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    split = StratifiedShuffleSplit(n_splits = 1,test_size = size,random_state = 42)\n",
    "\n",
    "    for train_index,test_index in split.split(data,data.iloc[:,-1]):\n",
    "        train_set = data.iloc[train_index,:]\n",
    "        test_set = data.iloc[test_index,:]\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51550edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalSplit(df, split_date): \n",
    "    \"\"\"\n",
    "    Split a DataFrame into a training set and a test set based on a split date.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        split_date (str): The date used to split the DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame, pd.DataFrame: The training set and test set DataFrames.\n",
    "    \"\"\"\n",
    "    # Convert 'date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Convert split_date to datetime\n",
    "    split_date = pd.Timestamp(split_date)\n",
    "    \n",
    "    # Split the DataFrame into training and test sets\n",
    "    train_set = df[df['Date'] < split_date]\n",
    "    test_set = df[df['Date'] >= split_date]\n",
    "    \n",
    "    return train_set, test_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "867a967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the last 10% data \n",
    "\n",
    "# window\n",
    "def sliding_window(data, window_size,anomaly_ratio):\n",
    "    # from last raw\n",
    "    for i in range(len(data)-1, window_size-2, -10):\n",
    "        data_slice = data[i-window_size+1:i+1]\n",
    "        ratio = (data_slice[\"Label\"] == 1).sum() / window_size*100\n",
    "        #print(ratio)\n",
    "        if anomaly_ratio*0.8 <= ratio <= anomaly_ratio*1.2:\n",
    "            #print(data_slice)\n",
    "            return data_slice\n",
    "\n",
    "\n",
    "def getLastSplit(data, size,anomaly_ratio):\n",
    "    data.sort_values(\"Datetime\", ascending=True, inplace=True)\n",
    "    #print(data)\n",
    "    row,col=data.shape\n",
    "    window_size = int(size*row)\n",
    "    test_set = sliding_window(data, window_size,anomaly_ratio)\n",
    "    if test_set is None:\n",
    "        print(\"no test\")\n",
    "    time = test_set.iloc[0,0]\n",
    "    #print(time)\n",
    "    train_set = data[data['Datetime'] < time]\n",
    "    print(len(train_set),len(test_set))\n",
    "    return train_set,test_set\n",
    "# windows keep the same rate of anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dc3d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute data error rate\n",
    "def comp_error_ratio(dataset):\n",
    "    instance = dataset[(dataset['Label']==1)]\n",
    "    rate=len(instance)/len(dataset)*100\n",
    "    return round(rate,2) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef49aad1",
   "metadata": {},
   "source": [
    "## Get random split\n",
    "\n",
    "60-20-20 Random split:\n",
    "- Training Set: 60% of the data\n",
    "- Validation Set: 20% of the data\n",
    "- Test Set: 20% of the data\n",
    "\n",
    "Temporal split: \n",
    "- Training Set: 2019-2020 \n",
    "- Test SetL 2021-2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c420d2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- PR_PF_4903220.csv ---------\n",
      "Random split:\n",
      "Train error rate: 0.16%\n",
      "Validate error rate: 0.16%\n",
      "Test error rate: 0.16%\n",
      "Train set size:  181009\n",
      "Validate set size:  60337\n",
      "Test set size:  60337\n",
      "\n",
      "\n",
      "Temporal split:\n",
      "Train error rate: 0.04%\n",
      "Test error rate: 0.33%\n",
      "Train set size:  125733\n",
      "Test set size:  175950\n",
      "\n",
      "\n",
      "-------- PR_PF_4903217.csv ---------\n",
      "Random split:\n",
      "Train error rate: 33.72%\n",
      "Validate error rate: 33.72%\n",
      "Test error rate: 33.72%\n",
      "Train set size:  179539\n",
      "Validate set size:  59847\n",
      "Test set size:  59847\n",
      "\n",
      "\n",
      "Temporal split:\n",
      "Train error rate: 57.65%\n",
      "Test error rate: 0.03%\n",
      "Train set size:  124294\n",
      "Test set size:  174939\n",
      "\n",
      "\n",
      "-------- PR_PF_4903058.csv ---------\n",
      "Random split:\n",
      "Train error rate: 42.02%\n",
      "Validate error rate: 42.02%\n",
      "Test error rate: 42.02%\n",
      "Train set size:  184254\n",
      "Validate set size:  61418\n",
      "Test set size:  61418\n",
      "\n",
      "\n",
      "Temporal split:\n",
      "Train error rate: 71.46%\n",
      "Test error rate: 0.73%\n",
      "Train set size:  127822\n",
      "Test set size:  179268\n",
      "\n",
      "\n",
      "-------- PR_PF_4903218.csv ---------\n",
      "Random split:\n",
      "Train error rate: 0.84%\n",
      "Validate error rate: 0.84%\n",
      "Test error rate: 0.84%\n",
      "Train set size:  175583\n",
      "Validate set size:  58528\n",
      "Test set size:  58528\n",
      "\n",
      "\n",
      "Temporal split:\n",
      "Train error rate: 0.74%\n",
      "Test error rate: 0.98%\n",
      "Train set size:  122524\n",
      "Test set size:  170115\n",
      "\n",
      "\n",
      "-------- PR_PF_4903052.csv ---------\n",
      "Random split:\n",
      "Train error rate: 0.69%\n",
      "Validate error rate: 0.69%\n",
      "Test error rate: 0.69%\n",
      "Train set size:  179000\n",
      "Validate set size:  59667\n",
      "Test set size:  59667\n",
      "\n",
      "\n",
      "Temporal split:\n",
      "Train error rate: 0.92%\n",
      "Test error rate: 0.36%\n",
      "Train set size:  123863\n",
      "Test set size:  174471\n",
      "\n",
      "\n",
      "-------- PR_PF_4903215.csv ---------\n",
      "Random split:\n",
      "Train error rate: 76.73%\n",
      "Validate error rate: 76.74%\n",
      "Test error rate: 76.73%\n",
      "Train set size:  184120\n",
      "Validate set size:  61374\n",
      "Test set size:  61374\n",
      "\n",
      "\n",
      "Temporal split:\n",
      "Train error rate: 100.0%\n",
      "Test error rate: 43.65%\n",
      "Train set size:  126702\n",
      "Test set size:  180166\n",
      "\n",
      "\n",
      "-------- PR_PF_4903054.csv ---------\n",
      "Random split:\n",
      "Train error rate: 0.22%\n",
      "Validate error rate: 0.22%\n",
      "Test error rate: 0.23%\n",
      "Train set size:  177455\n",
      "Validate set size:  59152\n",
      "Test set size:  59152\n",
      "\n",
      "\n",
      "Temporal split:\n",
      "Train error rate: 0.12%\n",
      "Test error rate: 0.38%\n",
      "Train set size:  123533\n",
      "Test set size:  172226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(input_dir)\n",
    "\n",
    "\n",
    "for file_name in files:\n",
    "    print(f'-------- {file_name} ---------')\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # ------ Random split\n",
    "    print('Random split:')\n",
    "    train_set1, temp = getRandomSplit(data,0.4) # random 60 40\n",
    "    val_set1, test_set1 = getRandomSplit(temp,0.5) # random 20 20\n",
    "    train_rate1 = comp_error_ratio(test_set1)\n",
    "    val_rate1 = comp_error_ratio(val_set1)\n",
    "    test_rate1 = comp_error_ratio(train_set1)\n",
    "\n",
    "    print(f\"Train error rate: {train_rate1}%\")\n",
    "    print(f\"Validate error rate: {val_rate1}%\")\n",
    "    print(f\"Test error rate: {test_rate1}%\")\n",
    "\n",
    "    print(\"Train set size: \",len(train_set1))\n",
    "    print(\"Validate set size: \",len(val_set1))\n",
    "    print(\"Test set size: \",len(test_set1))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    train_set1.to_csv(os.path.join(random_train_dir, f\"{file_name}\"), index=False)\n",
    "    val_set1.to_csv(os.path.join(random_val_dir, f\"{file_name}\"), index=False)\n",
    "    test_set1.to_csv(os.path.join(random_test_dir, f\"{file_name}\"), index=False)\n",
    "\n",
    "\n",
    "    # ------ Temporal split\n",
    "    print('Temporal split:')\n",
    "    train_set2, test_set2 = getTemporalSplit(data, '2021-01-01') # Split date: 2021-01-01\n",
    "    train_rate2 = comp_error_ratio(test_set2)\n",
    "    # val_rate2 = comp_error_ratio(val_set2)\n",
    "    test_rate2 = comp_error_ratio(train_set2)\n",
    "\n",
    "    print(f\"Train error rate: {train_rate2}%\")\n",
    "    # print(f\"Validate error rate: {val_rate2}%\")\n",
    "    print(f\"Test error rate: {test_rate2}%\")\n",
    "\n",
    "    print(\"Train set size: \",len(train_set2))\n",
    "    # print(\"Validate set size: \",len(val_set2))\n",
    "    print(\"Test set size: \",len(test_set2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    train_set2.to_csv(os.path.join(temporal_train_dir, f\"{file_name}\"), index=False)\n",
    "    # val_set2.to_csv(os.path.join(temporal_val_dir, f\"{file_name}\"), index=False)\n",
    "    test_set2.to_csv(os.path.join(temporal_test_dir, f\"{file_name}\"), index=False)\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3431b029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Normalized_date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>-1.704009</td>\n",
       "      <td>-2.107283</td>\n",
       "      <td>-2.423796</td>\n",
       "      <td>-0.893563</td>\n",
       "      <td>1.008039</td>\n",
       "      <td>0.978781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>-1.704009</td>\n",
       "      <td>-2.107283</td>\n",
       "      <td>-2.423796</td>\n",
       "      <td>-0.892623</td>\n",
       "      <td>1.031669</td>\n",
       "      <td>0.979516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>-1.704009</td>\n",
       "      <td>-2.107283</td>\n",
       "      <td>-2.423796</td>\n",
       "      <td>-0.891120</td>\n",
       "      <td>1.044469</td>\n",
       "      <td>0.979516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>-1.704009</td>\n",
       "      <td>-2.107283</td>\n",
       "      <td>-2.423796</td>\n",
       "      <td>-0.889554</td>\n",
       "      <td>1.034623</td>\n",
       "      <td>0.979149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>-1.704009</td>\n",
       "      <td>-2.107283</td>\n",
       "      <td>-2.423796</td>\n",
       "      <td>-0.887988</td>\n",
       "      <td>1.033639</td>\n",
       "      <td>0.979271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125728</th>\n",
       "      <td>125729</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>-0.303387</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.377426</td>\n",
       "      <td>-0.738406</td>\n",
       "      <td>1.198069</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125729</th>\n",
       "      <td>125730</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>-0.303387</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.377426</td>\n",
       "      <td>-0.738218</td>\n",
       "      <td>1.198069</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125730</th>\n",
       "      <td>125731</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>-0.303387</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.377426</td>\n",
       "      <td>-0.738030</td>\n",
       "      <td>1.197085</td>\n",
       "      <td>0.930491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125731</th>\n",
       "      <td>125732</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>-0.303387</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.377426</td>\n",
       "      <td>-0.737842</td>\n",
       "      <td>1.198069</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125732</th>\n",
       "      <td>125733</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>-0.303387</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.377426</td>\n",
       "      <td>-0.737717</td>\n",
       "      <td>1.198069</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125733 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       Date  Normalized_date  Latitude  Longitude  Pressure  \\\n",
       "0            1 2019-03-07        -1.704009 -2.107283  -2.423796 -0.893563   \n",
       "1            2 2019-03-07        -1.704009 -2.107283  -2.423796 -0.892623   \n",
       "2            3 2019-03-07        -1.704009 -2.107283  -2.423796 -0.891120   \n",
       "3            4 2019-03-07        -1.704009 -2.107283  -2.423796 -0.889554   \n",
       "4            5 2019-03-07        -1.704009 -2.107283  -2.423796 -0.887988   \n",
       "...        ...        ...              ...       ...        ...       ...   \n",
       "125728  125729 2020-12-24        -0.303387  0.447158   0.377426 -0.738406   \n",
       "125729  125730 2020-12-24        -0.303387  0.447158   0.377426 -0.738218   \n",
       "125730  125731 2020-12-24        -0.303387  0.447158   0.377426 -0.738030   \n",
       "125731  125732 2020-12-24        -0.303387  0.447158   0.377426 -0.737842   \n",
       "125732  125733 2020-12-24        -0.303387  0.447158   0.377426 -0.737717   \n",
       "\n",
       "        Salinity  Temperature  Label  \n",
       "0       1.008039     0.978781      0  \n",
       "1       1.031669     0.979516      0  \n",
       "2       1.044469     0.979516      0  \n",
       "3       1.034623     0.979149      0  \n",
       "4       1.033639     0.979271      0  \n",
       "...          ...          ...    ...  \n",
       "125728  1.198069     0.930368      0  \n",
       "125729  1.198069     0.930368      0  \n",
       "125730  1.197085     0.930491      0  \n",
       "125731  1.198069     0.930368      0  \n",
       "125732  1.198069     0.930368      0  \n",
       "\n",
       "[125733 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "328c8d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Normalized_date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125733</th>\n",
       "      <td>125734</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>-0.282101</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.455253</td>\n",
       "      <td>-0.892686</td>\n",
       "      <td>1.075977</td>\n",
       "      <td>0.845063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125734</th>\n",
       "      <td>125735</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>-0.282101</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.455253</td>\n",
       "      <td>-0.891120</td>\n",
       "      <td>1.075977</td>\n",
       "      <td>0.845063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125735</th>\n",
       "      <td>125736</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>-0.282101</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.455253</td>\n",
       "      <td>-0.889554</td>\n",
       "      <td>1.075977</td>\n",
       "      <td>0.845063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125736</th>\n",
       "      <td>125737</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>-0.282101</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.455253</td>\n",
       "      <td>-0.887988</td>\n",
       "      <td>1.075977</td>\n",
       "      <td>0.844573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125737</th>\n",
       "      <td>125738</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>-0.282101</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.455253</td>\n",
       "      <td>-0.886422</td>\n",
       "      <td>1.075977</td>\n",
       "      <td>0.844941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301678</th>\n",
       "      <td>301679</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1.718787</td>\n",
       "      <td>0.776962</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>-0.738531</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>0.619544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301679</th>\n",
       "      <td>301680</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1.718787</td>\n",
       "      <td>0.776962</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>-0.738281</td>\n",
       "      <td>0.596470</td>\n",
       "      <td>0.618686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301680</th>\n",
       "      <td>301681</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1.718787</td>\n",
       "      <td>0.776962</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>-0.738156</td>\n",
       "      <td>0.596470</td>\n",
       "      <td>0.616971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301681</th>\n",
       "      <td>301682</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1.718787</td>\n",
       "      <td>0.776962</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>-0.737968</td>\n",
       "      <td>0.592531</td>\n",
       "      <td>0.616235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301682</th>\n",
       "      <td>301683</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>1.718787</td>\n",
       "      <td>0.776962</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>-0.737842</td>\n",
       "      <td>0.589577</td>\n",
       "      <td>0.616235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175950 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       Date  Normalized_date  Latitude  Longitude  Pressure  \\\n",
       "125733  125734 2021-01-03        -0.282101  0.254899   0.455253 -0.892686   \n",
       "125734  125735 2021-01-03        -0.282101  0.254899   0.455253 -0.891120   \n",
       "125735  125736 2021-01-03        -0.282101  0.254899   0.455253 -0.889554   \n",
       "125736  125737 2021-01-03        -0.282101  0.254899   0.455253 -0.887988   \n",
       "125737  125738 2021-01-03        -0.282101  0.254899   0.455253 -0.886422   \n",
       "...        ...        ...              ...       ...        ...       ...   \n",
       "301678  301679 2023-08-01         1.718787  0.776962   0.512307 -0.738531   \n",
       "301679  301680 2023-08-01         1.718787  0.776962   0.512307 -0.738281   \n",
       "301680  301681 2023-08-01         1.718787  0.776962   0.512307 -0.738156   \n",
       "301681  301682 2023-08-01         1.718787  0.776962   0.512307 -0.737968   \n",
       "301682  301683 2023-08-01         1.718787  0.776962   0.512307 -0.737842   \n",
       "\n",
       "        Salinity  Temperature  Label  \n",
       "125733  1.075977     0.845063      0  \n",
       "125734  1.075977     0.845063      0  \n",
       "125735  1.075977     0.845063      0  \n",
       "125736  1.075977     0.844573      0  \n",
       "125737  1.075977     0.844941      0  \n",
       "...          ...          ...    ...  \n",
       "301678  0.594500     0.619544      0  \n",
       "301679  0.596470     0.618686      0  \n",
       "301680  0.596470     0.616971      0  \n",
       "301681  0.592531     0.616235      0  \n",
       "301682  0.589577     0.616235      0  \n",
       "\n",
       "[175950 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7704cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-quality-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
