{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "This notebook preprocesses data downloaded from the Argo data platform to experimental data. The preprocessing precedure follows the following steps: \n",
    "- Select relevant columns and drop NAN rows\n",
    "- Add global QC labels to each row\n",
    "- Rename columns\n",
    "- Normalize data (z-score standardization)\n",
    "\n",
    "See Argo QC flag scale @ ./argo_qc_flag_scale.png\n",
    "\n",
    "\n",
    "Input: \n",
    "- `../data/original_data/Atlantic_2019_03`\n",
    "\n",
    "Output: \n",
    "- `../data/preprocessed_data/Atlantic_2019_03`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6219bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c8d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = '../data/original_data/Atlantic_2019_03'\n",
    "PREPROCESSED_DATA_DIR = '../data/preprocessed_data/Atlantic_2019_03'\n",
    "NORMALIZED_DATA_DIR = '../data/preprocessed_data/Atlantic_2019_03/normalized'\n",
    "\n",
    "os.makedirs(PREPROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(NORMALIZED_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc08f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute data error rate\n",
    "def comp_error_ratio(dataset):\n",
    "    instance = dataset[(dataset['Label']==1)]\n",
    "    rate=len(instance)/len(dataset)*100\n",
    "    return round(rate,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b959f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add global QC label to each record. \n",
    "# If all QC are `1`, assign the label `0`(normal). Otherwise assign the label `1`(abnormal). \n",
    "def add_global_qc_label(df):\n",
    "    values = df[['DATE_QC', 'POSITION_QC', 'PRES_QC', 'PSAL_QC', 'TEMP_QC']]\n",
    "    is_all_normal = values.isin({1}).all(axis=1)\n",
    "    label_values = is_all_normal.map(lambda x: 0 if x else 1)\n",
    "    df['Label'] = label_values \n",
    "\n",
    "    print(f'Error rate: {comp_error_ratio(df)}%')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d34aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names\n",
    "column_map = {\n",
    "              # 'PLATFORM_CODE': 'Platform_code', \n",
    "              'ID': 'ID', \n",
    "              'DATE (YYYY-MM-DDTHH:MI:SSZ)': 'Datetime',\n",
    "              'LATITUDE (degree_north)': 'Latitude', \n",
    "              'LONGITUDE (degree_east)': 'Longitude', \n",
    "              'PRES (decibar)': 'Pressure', \n",
    "              'PSAL (psu)': 'Salinity', \n",
    "              'TEMP (degree_Celsius)': 'Temperature', \n",
    "              'Label': 'Label', \n",
    "            #   'PRES_QC': 'PRES_QC', \n",
    "            #   'TEMP_QC': 'TEMP_QC', \n",
    "            #   'PSAL_QC': 'PSAL_QC', \n",
    "              # 'PRES_ADJUSTED (decibar)': 'pressure_adjusted', \n",
    "              # '': '', \n",
    "             }\n",
    "def change_column_names(df): \n",
    "    df.rename(columns=column_map, inplace=True)\n",
    "    data = df[list(column_map.values())]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6dc127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def standardize_columns(df, columns):\n",
    "    df_standardized = df.copy()\n",
    "    for column in columns:\n",
    "        col_mean = df[column].mean()\n",
    "        col_std = df[column].std()\n",
    "        df_standardized[column] = (df[column] - col_mean) / col_std\n",
    "    return df_standardized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883b3d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "         Date  Value\n",
      "0  2022-01-01     10\n",
      "1  2022-02-01     20\n",
      "2  2022-03-01     30\n",
      "3  2022-04-01     40\n",
      "4  2022-05-01     50\n",
      "\n",
      "Normalized DataFrame:\n",
      "        Date  Value  Normalized_date\n",
      "0 2022-01-01     10        -1.269007\n",
      "1 2022-02-01     20        -0.613353\n",
      "2 2022-03-01     30        -0.021150\n",
      "3 2022-04-01     40         0.634503\n",
      "4 2022-05-01     50         1.269007\n"
     ]
    }
   ],
   "source": [
    "# Normalize date\n",
    "def normalize_date_column(df, date_column, reference_date=None):\n",
    "    df_normalized = df.copy()\n",
    "    df_normalized[date_column] = pd.to_datetime(df_normalized[date_column])\n",
    "    \n",
    "    if reference_date is None:\n",
    "        reference_date = df_normalized[date_column].min()\n",
    "\n",
    "    df_normalized['DaysSinceReference'] = (df_normalized[date_column] - reference_date).dt.days\n",
    "    \n",
    "    col_mean = df_normalized['DaysSinceReference'].mean()\n",
    "    col_std = df_normalized['DaysSinceReference'].std()\n",
    "    \n",
    "    df_normalized.insert(2, 'Normalized_date', (df_normalized['DaysSinceReference'] - col_mean) / col_std)\n",
    "    # df_normalized['Normalized_date'] = (df_normalized['DaysSinceReference'] - col_mean) / col_std\n",
    "    \n",
    "    return df_normalized.drop(columns=['DaysSinceReference'])\n",
    "\n",
    "# Sample DataFrame with a date column\n",
    "data = {'Date': ['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01', '2022-05-01'],\n",
    "        'Value': [10, 20, 30, 40, 50]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize the 'Date' column using a reference date of '2010-01-01'\n",
    "normalized_df = normalize_date_column(df, date_column='Date', reference_date=pd.Timestamp('2010-03-20'))\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nNormalized DataFrame:\")\n",
    "print(normalized_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a39430",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c981a406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dir: ../data/original_data/Atlantic_2019_03\n",
      "Output dir: ../data/preprocessed_data/Atlantic_2019_03\n",
      "-------- PR_PF_4903220.csv --------\n",
      "Error rate: 0.16%\n",
      "-------- PR_PF_4903217.csv --------\n",
      "Error rate: 33.72%\n",
      "-------- PR_PF_4903058.csv --------\n",
      "Error rate: 42.02%\n",
      "-------- PR_PF_4903218.csv --------\n",
      "Error rate: 0.84%\n",
      "-------- PR_PF_4903052.csv --------\n",
      "Error rate: 0.69%\n",
      "-------- PR_PF_4903215.csv --------\n",
      "Error rate: 76.73%\n",
      "-------- PR_PF_4903054.csv --------\n",
      "Error rate: 0.23%\n"
     ]
    }
   ],
   "source": [
    "input_dir = ORIGINAL_DATA_DIR\n",
    "output_dir = PREPROCESSED_DATA_DIR\n",
    "normalized_dir = NORMALIZED_DATA_DIR\n",
    "file_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "\n",
    "print(f'Input dir: {input_dir}')\n",
    "print(f'Output dir: {output_dir}')\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        normalized_path = os.path.join(normalized_dir, filename)\n",
    "\n",
    "        df = pd.read_csv(input_path)\n",
    "        print(f'-------- {filename} --------')\n",
    "\n",
    "        # Select relevant columns\n",
    "        df = df[['DATE (YYYY-MM-DDTHH:MI:SSZ)', 'DATE_QC',\n",
    "       'LATITUDE (degree_north)', 'LONGITUDE (degree_east)', 'POSITION_QC',\n",
    "       'PRES (decibar)', 'PRES_QC', 'PSAL (psu)', 'PSAL_QC',\n",
    "       'TEMP (degree_Celsius)', 'TEMP_QC']]\n",
    "        \n",
    "        # Drop NAN rows\n",
    "        df= df.dropna()\n",
    "\n",
    "        # Add ID to each sample\n",
    "        df.insert(0, 'ID', range(1, len(df)+1))\n",
    "\n",
    "        # Add global QC labels\n",
    "        df = add_global_qc_label(df)\n",
    "        \n",
    "        # Change column names\n",
    "        df = change_column_names(df)\n",
    "\n",
    "        # Save the preprocessed data\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        # Normalize the data\n",
    "        df = standardize_columns(df, ['Latitude','Longitude','Pressure','Salinity','Temperature'])\n",
    "\n",
    "        # Normalize the date\n",
    "        df.insert(1, 'Date', pd.to_datetime(df['Datetime']).dt.date)\n",
    "        df.drop('Datetime', axis=1, inplace=True)\n",
    "        df = normalize_date_column(df, date_column='Date', reference_date=pd.Timestamp('2015-01-01'))\n",
    "        \n",
    "        # Save the normalized data\n",
    "        df.to_csv(normalized_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc92b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Normalized_date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>-1.695561</td>\n",
       "      <td>-0.680361</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>-0.903329</td>\n",
       "      <td>0.913626</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>-1.695561</td>\n",
       "      <td>-0.680361</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>-0.902453</td>\n",
       "      <td>0.902150</td>\n",
       "      <td>0.822605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>-1.695561</td>\n",
       "      <td>-0.680361</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>-0.900953</td>\n",
       "      <td>0.919805</td>\n",
       "      <td>0.823276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>-1.695561</td>\n",
       "      <td>-0.680361</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>-0.899328</td>\n",
       "      <td>0.916274</td>\n",
       "      <td>0.824060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>-1.695561</td>\n",
       "      <td>-0.680361</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>-0.897765</td>\n",
       "      <td>0.916274</td>\n",
       "      <td>0.824396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295754</th>\n",
       "      <td>295755</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>1.728835</td>\n",
       "      <td>-1.441171</td>\n",
       "      <td>1.993646</td>\n",
       "      <td>-0.748427</td>\n",
       "      <td>0.923336</td>\n",
       "      <td>0.804243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295755</th>\n",
       "      <td>295756</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>1.728835</td>\n",
       "      <td>-1.441171</td>\n",
       "      <td>1.993646</td>\n",
       "      <td>-0.748240</td>\n",
       "      <td>0.925102</td>\n",
       "      <td>0.804131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295756</th>\n",
       "      <td>295757</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>1.728835</td>\n",
       "      <td>-1.441171</td>\n",
       "      <td>1.993646</td>\n",
       "      <td>-0.747990</td>\n",
       "      <td>0.923336</td>\n",
       "      <td>0.804243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295757</th>\n",
       "      <td>295758</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>1.728835</td>\n",
       "      <td>-1.441171</td>\n",
       "      <td>1.993646</td>\n",
       "      <td>-0.747865</td>\n",
       "      <td>0.922454</td>\n",
       "      <td>0.804243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295758</th>\n",
       "      <td>295759</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>1.728835</td>\n",
       "      <td>-1.441171</td>\n",
       "      <td>1.993646</td>\n",
       "      <td>-0.747802</td>\n",
       "      <td>0.923336</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295759 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       Date  Normalized_date  Latitude  Longitude  Pressure  \\\n",
       "0            1 2019-03-23        -1.695561 -0.680361   0.026959 -0.903329   \n",
       "1            2 2019-03-23        -1.695561 -0.680361   0.026959 -0.902453   \n",
       "2            3 2019-03-23        -1.695561 -0.680361   0.026959 -0.900953   \n",
       "3            4 2019-03-23        -1.695561 -0.680361   0.026959 -0.899328   \n",
       "4            5 2019-03-23        -1.695561 -0.680361   0.026959 -0.897765   \n",
       "...        ...        ...              ...       ...        ...       ...   \n",
       "295754  295755 2023-08-05         1.728835 -1.441171   1.993646 -0.748427   \n",
       "295755  295756 2023-08-05         1.728835 -1.441171   1.993646 -0.748240   \n",
       "295756  295757 2023-08-05         1.728835 -1.441171   1.993646 -0.747990   \n",
       "295757  295758 2023-08-05         1.728835 -1.441171   1.993646 -0.747865   \n",
       "295758  295759 2023-08-05         1.728835 -1.441171   1.993646 -0.747802   \n",
       "\n",
       "        Salinity  Temperature  Label  \n",
       "0       0.913626     0.822493      0  \n",
       "1       0.902150     0.822605      0  \n",
       "2       0.919805     0.823276      0  \n",
       "3       0.916274     0.824060      0  \n",
       "4       0.916274     0.824396      0  \n",
       "...          ...          ...    ...  \n",
       "295754  0.923336     0.804243      0  \n",
       "295755  0.925102     0.804131      0  \n",
       "295756  0.923336     0.804243      0  \n",
       "295757  0.922454     0.804243      0  \n",
       "295758  0.923336     0.804019      0  \n",
       "\n",
       "[295759 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feabcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e0099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-quality-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
